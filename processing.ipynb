{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactoring lost histogram processing file - IT IS RECOVERED!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all packages\n",
    "load up IA file as dataframe\n",
    "load up joined shapefile with census info\n",
    "loop trhough each row, write to a new file, new headers, as well as old, for each new variable create it by saying if a value of a row's column so fow[23] for example is great than or equal to xyz then the new variable is true or false respectively, add new variable value to row, then write all to new csv file\n",
    "drop unneeded columns\n",
    "dg loc so its only 50 rows\n",
    "change price to be a float and without funny symbols\n",
    "create new variables (that you'll find listed out on the csv file from yesterday)\n",
    "\n",
    "when you have the new variable in the new csv file, lets load that into qgis and join it again to the census shapefile, watch filenames\n",
    "then we'll have a new variables, with census data, geolocated file! all in one place! \n",
    "then drop more columns that don't need (from census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stateofplace/.virtualenvs/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import geojson\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import matplotlib as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import describe\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import csv\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path \n",
    "import os\n",
    "from datetime import date, time, datetime\n",
    "from dateutil import tz #for dealing with timezone\n",
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_03_23_18_40_54\n"
     ]
    }
   ],
   "source": [
    "def get_time():\n",
    "    today = date.today()\n",
    "    current_time = time(datetime.now().hour, datetime.now().minute, datetime.now().second)\n",
    "    date_today = datetime.combine(today, current_time)\n",
    "    new_date_time = str(date_today).replace(\" \", \"_\").replace(\"-\", \"_\").replace(\":\", \"_\")\n",
    "    return(new_date_time)\n",
    "print(get_time())\n",
    "new_date_time = get_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(ia, census_ia): \n",
    "    #load and create dataframes\n",
    "    ia_df = pd.read_csv(ia)\n",
    "    #drop\n",
    "    ia_df.drop(columns=[\"scrape_id\", \"bathrooms_text\",\"host_verifications\", \"host_neighbourhood\",\"property_type\", \"amenities\", \"host_verifications\", \"neighbourhood\", \"host_listings_count\", \"picture_url\",\"host_url\", \"description\", \"neighborhood_overview\", \"host_about\", \"host_response_time\", \"host_response_rate\", 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_has_profile_pic', 'host_identity_verified', 'calendar_updated', 'has_availability', 'calendar_last_scraped', 'number_of_reviews', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'neighbourhood_group_cleansed', 'beds', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'bathrooms', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms'], inplace=True)\n",
    "    #rename columns ? \n",
    "    #trim columns \n",
    "    #ia_df = ia_df.loc[:50, :]\n",
    "    #handle shape file joined, we need it for some variable creation, but doens't need to be a airbnb joined one, just the census info is fine\n",
    "    census_gdf = geopandas.read_file(census_ia)\n",
    "    return(ia_df, census_gdf)\n",
    "ia_df_clean, census_gdf = load_files(\"../scrap_work/florence_listings_jan_27.csv\", \"../thesis_app/airbnb_census_joined.shp\") #using the shapefile with no airbnb data yet makes more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/m6366gw17qd8jtbtczp7ttnc0000gp/T/ipykernel_40914/1059505739.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dataframe['price'] = dataframe['price'].str.replace(\"$\", \"\").str.replace(',', '')\n"
     ]
    }
   ],
   "source": [
    "#will only work once i think\n",
    "def fixpricing_file(dataframe):\n",
    "    #price adjust\n",
    "    dataframe['price'] = dataframe['price'].str.replace(\"$\", \"\").str.replace(',', '')\n",
    "    dataframe['price'] = pd.to_numeric(dataframe['price'])\n",
    "    #tests\n",
    "    # print(dataframe['price']) #no special characters \n",
    "    # print(type(dataframe['price'])) #float not string \n",
    "    return dataframe\n",
    "\n",
    "ia_df_clean = fixpricing_file(ia_df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../thesis_app/Out_CSV/ia_1_27_222022_03_23_18_40_54.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'csv' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/csv.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_csv(dataframe):\n",
    "    filepath = Path('../thesis_app/Out_CSV/ia_1_27_22' + new_date_time + '.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True) \n",
    "    dataframe.to_csv(filepath)\n",
    "    #tests\n",
    "    print(filepath)\n",
    "    return csv\n",
    "df_to_csv(ia_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.writer at 0x7fd788b20ea0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_new_variables(cleaned_file_input, file_output, dataframe):\n",
    "    #do a lot of processing\n",
    "    all = []\n",
    "    with open(cleaned_file_input, 'r') as file:\n",
    "        with open(file_output, 'w') as newfile:\n",
    "            csvwriter = csv.writer(newfile,lineterminator='\\n')\n",
    "            csvreader = csv.reader(file)\n",
    "            #extract headers\n",
    "            header = next(csvreader)\n",
    "            new_headers = ['days_rented', 'rounded_revenue', 'is_hotel', 'is_entire', 'many_listings', 'only_1_listing', 'only_2_listings', 'host_florence', 'has_liscense', 'is_instant_bookable', 'global_total_listings', 'dist_duomo', 'is_centro', 'is_gavinana', 'is_isolotto', 'is_rifredi', 'is_campo', 'listing_revenue_exceed_LTR', 'effected_by_policy_1', 'effected_by_policy_2', 'effected_by_policy_3', 'effected_by_policy_4', 'commercial']\n",
    "            for item in new_headers:\n",
    "                header.append(item)\n",
    "            all.append(header)\n",
    "            for row in csvreader:\n",
    "            #index row \n",
    "                listing_row_id = int(row[0])\n",
    "                # total global and local listings\n",
    "                global_total_listings = int(row[9]) + int(row[25]) \n",
    "                #dist_duomo\n",
    "                duomo_coords = (43.7731, 11.2560)\n",
    "                #listing_coords = lat, long\n",
    "                listing_coords = (row[11], row[12])\n",
    "                ##dist_duomo = duomo_coords - listing_coords\n",
    "                dist_duomo = (distance.distance(duomo_coords, listing_coords).m)\n",
    "                #has_liscense\n",
    "                if len(row[23]) > 0:\n",
    "                    has_liscense = 1\n",
    "                else:\n",
    "                    has_liscense = 0\n",
    "                #is_instant_bookable\n",
    "                if row[24] == 't':\n",
    "                    is_instant_bookable = 1\n",
    "                else:\n",
    "                    is_instant_bookable = 0\n",
    "                #getting info for \"host_florence\" success\n",
    "                if (\"Florence\" or \"Firenze\") in row[8]:\n",
    "                    host_florence = 1\n",
    "                else:\n",
    "                    host_florence = 0\n",
    "                    #print(host_florence)\n",
    "                #getting info for \"is_centro\" success\n",
    "                #get better average rent data just guessed from idealista\n",
    "                if \"Centro\" in row[10]:\n",
    "                    is_centro = 1\n",
    "                    neighborhood_rent = 1000 * 12\n",
    "                else:\n",
    "                    is_centro = 0\n",
    "                #is_campo success\n",
    "                if \"Campo\" in row[10]:\n",
    "                    is_campo = 1\n",
    "                    neighborhood_rent = 700 * 12\n",
    "                else:\n",
    "                    is_campo = 0\n",
    "                #is_rifredi success\n",
    "                if \"Rifredi\" in row[10]:\n",
    "                    is_rifredi = 1\n",
    "                    neighborhood_rent = 600 * 12\n",
    "                else:\n",
    "                    is_rifredi = 0\n",
    "                if \"Isolotto\" in row[10]:\n",
    "                    is_isolotto = 1\n",
    "                    neighborhood_rent = 400 * 12\n",
    "                else:\n",
    "                    is_isolotto = 0\n",
    "                if \"Gavinana\" in row[10]:\n",
    "                    is_gavinana = 1\n",
    "                    neighborhood_rent = 900 * 12\n",
    "                else:\n",
    "                    is_gavinana = 0\n",
    "                #many_listings variable success\n",
    "                if int(row[9]) > 2:\n",
    "                    many_listings = 1\n",
    "                else:\n",
    "                    many_listings = 0\n",
    "                #only_1 success\n",
    "                if int(row[9]) == 1:\n",
    "                    only_1_listing = 1\n",
    "                else: \n",
    "                    only_1_listing = 0\n",
    "                #only_2 success\n",
    "                if int(row[9]) == 2:\n",
    "                    only_2_listings = 1\n",
    "                else:\n",
    "                    only_2_listings = 0\n",
    "                #is_entire success \n",
    "                if row[13] == 'Entire home/apt':\n",
    "                    is_entire = 1\n",
    "                else:\n",
    "                    is_entire = 0\n",
    "                #is_hotel success\n",
    "                if row[13] == 'Hotel room':\n",
    "                    is_hotel = 1\n",
    "                else:\n",
    "                    is_hotel = 0\n",
    "                #days_rented\n",
    "                #TODO check against boston and CA gov method\n",
    "                days_rented = (int(row[21])/.7)*2.6\n",
    "                #thought I handeled this in the price fix def\n",
    "                #revenue #have to strip the string for price then turn into float\n",
    "                price_stripped_dollar = row[16].strip('$')\n",
    "                price_replaced_comma = price_stripped_dollar.replace(',','')\n",
    "                new_price = float(price_replaced_comma)\n",
    "                #yearly revenue\n",
    "                revenue = days_rented * new_price\n",
    "                rounded_revenue = round(revenue, 2)\n",
    "                #year and month\n",
    "                date_scraped = row[3]\n",
    "                #tests\n",
    "                #print(type(date_scraped))\n",
    "                #print(date_scraped.split('-'))\n",
    "                year = date_scraped.split('-')[0]\n",
    "                month = date_scraped.split('-')[1]\n",
    "                day = date_scraped.split('-')[2]\n",
    "                #commercial\n",
    "                if dataframe.loc[listing_row_id, 'host_total_listings_count'] > 2:\n",
    "                    commercial = 1\n",
    "                elif host_florence == 0:\n",
    "                    commercial = 1\n",
    "                else:\n",
    "                    commercial = 0\n",
    "                #very_likely_commercial\n",
    "                if dataframe.loc[listing_row_id, 'host_total_listings_count'] > 2 and dataframe.loc[listing_row_id, 'instant_bookable'] == 1:\n",
    "                    very_likely_commercial = 1\n",
    "                else:\n",
    "                    very_likely_commercial = 0\n",
    "\n",
    "                #effected_by_policy_x (1-liscense,2- -is entire, 3-2 listing max, 4-day limit 90) #switched 2 and 4 from origingal \n",
    "                if license == 0:\n",
    "                    effected_by_policy_1 = 1\n",
    "                else: \n",
    "                    effected_by_policy_1 = 0\n",
    "                if is_entire == 1:\n",
    "                    effected_by_policy_2 = 1\n",
    "                else:\n",
    "                    effected_by_policy_2 = 0\n",
    "                #man_listings is more than 2 \n",
    "                if many_listings == 1:\n",
    "                    effected_by_policy_3 = 1\n",
    "                else:\n",
    "                    effected_by_policy_3 = 0\n",
    "                if int(row[20]) > 90:\n",
    "                    effected_by_policy_4 = 1\n",
    "                else:\n",
    "                    effected_by_policy_4 = 0\n",
    "                #listing_revenue_exceed_LTR\n",
    "                #if yearly revenue exceeds average rent per neighborhood x12\n",
    "                #have to skip first one where its '' TODO: make sure for sure its only the first row that is throwing htis error but for now we don't even use these variables so not worried \n",
    "                try: yearly_revenue_room = rounded_revenue / float(row[15])\n",
    "                # print('yearly_revenue_room is:' + str(yearly_revenue_room))\n",
    "                except Exception:\n",
    "                    pass\n",
    "                neighborhood_LTR_room = neighborhood_rent\n",
    "                # print('neighborhood_LTR_room is:' + str(neighborhood_LTR_room))\n",
    "                if yearly_revenue_room > neighborhood_LTR_room:\n",
    "                    listing_revenue_exceed_LTR = 1\n",
    "                else:\n",
    "                    listing_revenue_exceed_LTR = 0\n",
    "                # print('is listing_revenue_exceed_LTR true?:' + str(listing_revenue_exceed_LTR))\n",
    "\n",
    "                new_variables = [days_rented, rounded_revenue, is_hotel, is_entire, many_listings, only_1_listing, only_2_listings, host_florence, has_liscense, is_instant_bookable, global_total_listings, dist_duomo, is_centro, is_gavinana, is_isolotto, is_rifredi, is_campo, listing_revenue_exceed_LTR, effected_by_policy_1, effected_by_policy_2, effected_by_policy_3, effected_by_policy_4, commercial]\n",
    "                for item in new_variables:\n",
    "                    row.append(item)\n",
    "                #adding entire row to all \n",
    "                all.append(row)\n",
    "            #writing all rows to new out file\n",
    "            csvwriter.writerows(all)\n",
    "    return csvwriter\n",
    "create_new_variables('../thesis_app/Out_CSV/ia_1_27_222022_03_23_18_40_54.csv', '../thesis_app/Out_CSV/ia_1_27_222022_03_23_18_40_54_new_variables.csv', ia_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.writer at 0x7fd7868604a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_geocensus_variables(ia_newvar_file_input, file_output, geodataframe):\n",
    "#need the joined gdf with airbnb data for the stats on census because we use the listing row id of the airbnb file which only matches with the gdf because it has airnbb data in it... maybe not necessary these variables at all anyway...we loop through csv file with 51 airbnb lisitings...to match with census info.. \n",
    "    all = []\n",
    "    with open(ia_newvar_file_input, 'r') as file:\n",
    "        with open(file_output, 'w') as newfile:\n",
    "            csvwriter = csv.writer(newfile,lineterminator='\\n')\n",
    "            csvreader = csv.reader(file)\n",
    "            #extract headers\n",
    "            header = next(csvreader)\n",
    "            new_headers = ['census_tract_id', 'num_residents_census', 'num_households_census', 'res_buildings_census', 'num_bedrooms_census', 'num_household_renters_census', 'num_household_owners_census']\n",
    "            for item in new_headers:\n",
    "                header.append(item)\n",
    "            all.append(header)\n",
    "            for row in csvreader:\n",
    "            #index row \n",
    "                listing_row_id = int(row[0])\n",
    "            \n",
    "                #census_tract_id_sez2011\n",
    "                census_tract_id = geodataframe.loc[listing_row_id, 'SEZ2011']\n",
    "                #census data points \n",
    "                columns = ['P1', 'A47', 'A46', 'PF1', 'E3', 'E27', 'SEZ2011']\n",
    "                #number of residents per census tract P1\n",
    "                num_residents_census = (geodataframe.loc[listing_row_id, 'P1'])\n",
    "                #number of households per census tract PF1\n",
    "                num_households_census = (geodataframe.loc[listing_row_id, 'PF1'])\n",
    "                #number of residential buildings per census tract E3\n",
    "                res_buildings_census = (geodataframe.loc[listing_row_id, 'E3'])\n",
    "                # number of bedrooms per census tract E27\n",
    "                num_bedrooms_census = (geodataframe.loc[listing_row_id, 'E27'])\n",
    "                #number of household renters per census tract  A46 \n",
    "                num_household_renters_census = (geodataframe.loc[listing_row_id, 'A46'])\n",
    "                #number of household homeowners per census tract A47\n",
    "                num_household_owners_census = (geodataframe.loc[listing_row_id, 'A47'])\n",
    "                #adding new variable to row for each row in file\n",
    "                \n",
    "                new_variables = [census_tract_id, num_residents_census, num_households_census, res_buildings_census, num_bedrooms_census, num_household_renters_census, num_household_owners_census]\n",
    "                for item in new_variables:\n",
    "                    row.append(item)\n",
    "                #adding entire row to all \n",
    "                all.append(row)\n",
    "            #writing all rows to new out file\n",
    "            csvwriter.writerows(all)\n",
    "    return csvwriter\n",
    "create_geocensus_variables('../thesis_app/Out_CSV/ia_1_27_222022_03_23_18_40_54_new_variables.csv', '../thesis_app/Out_CSV/ia_1_27_222022_03_23_18_40_54_new_variables_census.csv', census_gdf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48b856948ce7543cb867bf61cc6302f9f01d5517ca34fe5612991cf2c8c52d4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.virtualenvs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
